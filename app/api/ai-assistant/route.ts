import { NextRequest, NextResponse } from 'next/server'
import { API_CONFIG, LOCAL_AI_CONFIG } from '@/lib/api-config'
import { callLocalLLM, checkLocalAIHealth, checkOllamaHealth, checkAIBackendHealth } from '@/lib/local-llm-client'
import { createPerformanceMiddleware, trackLLMRequest, trackProviderHealth, trackFeatureUsage } from '@/lib/monitoring'

export async function POST(request: NextRequest) {
  const endpoint = 'ai-assistant'
  const performanceHandler = createPerformanceMiddleware(endpoint)
  
  return performanceHandler(async () => {
    let language = 'en' // Default language
    try {
      const requestBody = await request.json()
      const { message } = requestBody
      language = requestBody.language || 'en'

      if (!message || typeof message !== 'string') {
        return NextResponse.json(
          { 
            success: false,
            error: 'Message is required and must be a string' 
          },
          { status: 400 }
        )
      }

      // Input sanitization and validation
      const sanitizedMessage = message.slice(0, LOCAL_AI_CONFIG.SECURITY.MAX_INPUT_LENGTH)
      
      // Check for blocked patterns
      const hasBlockedPattern = LOCAL_AI_CONFIG.SECURITY.BLOCKED_PATTERNS.some(
        (pattern: RegExp) => pattern.test(sanitizedMessage)
      )
      
      if (hasBlockedPattern) {
        return NextResponse.json(
          { 
            success: false,
            error: 'Message contains blocked content' 
          },
          { status: 400 }
        )
      }
      
      // Track feature usage
      trackFeatureUsage('ai_assistant', 'chat')
    
    // Try Local AI providers first if enabled
    if (LOCAL_AI_CONFIG.ENABLED) {
      try {
        console.log('ЁЯдЦ Using Local AI providers for farming assistance...')
        
        const startTime = Date.now()
        const localAIResponse = await callLocalLLM({
          prompt: sanitizedMessage,
          language: language,
          temperature: 0.7,
          max_tokens: 1000
        })
        
        const responseTime = Date.now() - startTime
        
        // Track LLM request metrics
        trackLLMRequest(localAIResponse.source, localAIResponse.model, responseTime, false)
        
        // Track provider health
        trackProviderHealth(localAIResponse.source, true, responseTime)

        // Log performance metrics
        console.log(`тЬЕ Local AI responded via ${localAIResponse.source} in ${responseTime}ms`)

        return NextResponse.json({
          success: true,
          response: localAIResponse.content,
          language: localAIResponse.language,
          source: localAIResponse.source,
          model: localAIResponse.model,
          response_time: localAIResponse.response_time,
          tokens_used: localAIResponse.tokens_used,
          confidence: localAIResponse.confidence,
          metadata: localAIResponse.metadata,
          timestamp: new Date().toISOString()
        })

      } catch (error) {
        console.error('тЭМ All local AI providers failed:', error)
        
        // Track provider failure
        trackProviderHealth('localai', false)
        
        // Continue to external providers as fallback
        console.log('тЪая╕П Falling back to external AI providers...')
      }
    }

    // Try OpenAI if local AI failed and API key is available
    if (API_CONFIG.OPENAI.API_KEY) {
      try {
        console.log('ЁЯМР Using OpenAI API...')
        
        const startTime = Date.now()
        
        const systemPrompt = `You are an AI farming assistant for Indian farmers. Provide practical, actionable advice about:
        - Crop cultivation and care
        - Pest and disease management  
        - Weather-based farming decisions
        - Market timing and pricing
        - Sustainable farming practices
        
        Keep responses simple, practical, and relevant to Indian agriculture. If the user asks in Hindi or other Indian languages, respond in that language.
        
        User's language preference: ${language}`

        const response = await fetch(`${API_CONFIG.OPENAI.BASE_URL}/chat/completions`, {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${API_CONFIG.OPENAI.API_KEY}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            model: API_CONFIG.OPENAI.MODEL,
            messages: [
              { role: 'system', content: systemPrompt },
              { role: 'user', content: sanitizedMessage }
            ],
            max_tokens: API_CONFIG.OPENAI.MAX_TOKENS,
            temperature: API_CONFIG.OPENAI.TEMPERATURE
          })
        })

        if (!response.ok) {
          throw new Error(`OpenAI API error: ${response.status}`)
        }

        const data = await response.json()
        const aiResponse = data.choices[0]?.message?.content || 'Sorry, I could not generate a response.'
        
        const responseTime = Date.now() - startTime
        
        // Track LLM request metrics
        trackLLMRequest('openai', API_CONFIG.OPENAI.MODEL, responseTime, false)
        trackProviderHealth('openai', true, responseTime)

        return NextResponse.json({
          success: true,
          response: aiResponse,
          language: language,
          source: 'openai',
          model: API_CONFIG.OPENAI.MODEL,
          response_time: responseTime,
          timestamp: new Date().toISOString()
        })

      } catch (error) {
        console.error('тЭМ OpenAI API failed:', error)
        
        // Track provider failure
        trackProviderHealth('openai', false)
      }
    }

    // Final fallback to mock response
    console.log('ЁЯФД Using mock response as final fallback...')
    
    const mockResponse = getMockFarmingResponse(sanitizedMessage, language)
    
    // Track fallback usage
    trackLLMRequest('mock', 'fallback', 0, false)
    
    return NextResponse.json({
      success: true,
      response: mockResponse,
      language: language,
      source: 'mock',
      model: 'fallback',
      timestamp: new Date().toISOString(),
      warning: 'Using fallback response - consider setting up local AI or external API keys'
    })

  } catch (error) {
    console.error('тЭМ AI Assistant critical error:', error)
    
    // Track critical error
    trackLLMRequest('system', 'error', 0, true)
    
    // Emergency fallback - use the language from the request or default to 'en'
    const responseLanguage = language || 'en'
    const emergencyResponse = {
      en: "I'm temporarily unable to provide assistance. Please try again in a moment, or contact your local agricultural extension office for immediate help.",
      hi: "рдореИрдВ рдЕрд╕реНрдерд╛рдпреА рд░реВрдк рд╕реЗ рд╕рд╣рд╛рдпрддрд╛ рдкреНрд░рджрд╛рди рдХрд░рдиреЗ рдореЗрдВ рдЕрд╕рдорд░реНрде рд╣реВрдБред рдХреГрдкрдпрд╛ рдПрдХ рдХреНрд╖рдг рдореЗрдВ рдлрд┐рд░ рд╕реЗ рдХреЛрд╢рд┐рд╢ рдХрд░реЗрдВ, рдпрд╛ рддрддреНрдХрд╛рд▓ рд╕рд╣рд╛рдпрддрд╛ рдХреЗ рд▓рд┐рдП рдЕрдкрдиреЗ рд╕реНрдерд╛рдиреАрдп рдХреГрд╖рд┐ рд╡рд┐рд╕реНрддрд╛рд░ рдХрд╛рд░реНрдпрд╛рд▓рдп рд╕реЗ рд╕рдВрдкрд░реНрдХ рдХрд░реЗрдВред"
    }
    
    return NextResponse.json({
      success: false,
      error: 'Service temporarily unavailable',
      response: emergencyResponse[responseLanguage as keyof typeof emergencyResponse] || emergencyResponse.en,
      source: 'emergency_fallback',
      timestamp: new Date().toISOString()
    }, { status: 500 })
  }
  })
}

// Mock farming responses for development/fallback
function getMockFarmingResponse(message: string, language: string): string {
  const responses = {
    en: [
      "Based on current weather conditions, I recommend checking your crop's water needs. Ensure proper drainage if rain is expected.",
      "For healthy crop growth, consider applying organic fertilizer during the early morning hours when temperature is cooler.",
      "Monitor your plants for any signs of pest damage. Early detection helps in better crop management.",
      "The best time for harvesting depends on your crop type. Check the color and firmness of fruits/grains regularly.",
      "Consider crop rotation to maintain soil fertility. Legumes like beans can help fix nitrogen in the soil."
    ],
    hi: [
      "рдореМрдЬреВрджрд╛ рдореМрд╕рдо рдХреА рд╕реНрдерд┐рддрд┐ рдХреЗ рдЖрдзрд╛рд░ рдкрд░, рдореИрдВ рдЖрдкрдХреА рдлрд╕рд▓ рдХреА рдкрд╛рдиреА рдХреА рдЬрд░реВрд░рддреЛрдВ рдХреА рдЬрд╛рдВрдЪ рдХрд░рдиреЗ рдХреА рд╕рд▓рд╛рд╣ рджреЗрддрд╛ рд╣реВрдВред",
      "рд╕реНрд╡рд╕реНрде рдлрд╕рд▓ рд╡рд┐рдХрд╛рд╕ рдХреЗ рд▓рд┐рдП, рд╕реБрдмрд╣ рдЬрд▓реНрджреА рдЬрдм рддрд╛рдкрдорд╛рди рдардВрдбрд╛ рд╣реЛ рддрдм рдЬреИрд╡рд┐рдХ рдЙрд░реНрд╡рд░рдХ рдХрд╛ рдкреНрд░рдпреЛрдЧ рдХрд░реЗрдВред",
      "рдХреАрдЯ рдХреНрд╖рддрд┐ рдХреЗ рдХрд┐рд╕реА рднреА рд╕рдВрдХреЗрдд рдХреЗ рд▓рд┐рдП рдЕрдкрдиреЗ рдкреМрдзреЛрдВ рдХреА рдирд┐рдЧрд░рд╛рдиреА рдХрд░реЗрдВред",
      "рдХрдЯрд╛рдИ рдХрд╛ рд╕рдмрд╕реЗ рдЕрдЪреНрдЫрд╛ рд╕рдордп рдЖрдкрдХреА рдлрд╕рд▓ рдХреЗ рдкреНрд░рдХрд╛рд░ рдкрд░ рдирд┐рд░реНрднрд░ рдХрд░рддрд╛ рд╣реИред",
      "рдорд┐рдЯреНрдЯреА рдХреА рдЙрд░реНрд╡рд░рддрд╛ рдмрдирд╛рдП рд░рдЦрдиреЗ рдХреЗ рд▓рд┐рдП рдлрд╕рд▓ рдЪрдХреНрд░ рдкрд░ рд╡рд┐рдЪрд╛рд░ рдХрд░реЗрдВред"
    ],
    kn: [
      "р▓кр│Нр▓░р▓╕р│Нр▓др│Бр▓д р▓╣р▓╡р▓╛р▓ор▓╛р▓и р▓кр▓░р▓┐р▓╕р│Нр▓ер▓┐р▓др▓┐р▓Чр▓│ р▓Жр▓зр▓╛р▓░р▓ж р▓ор│Зр▓▓р│Ж, р▓ир▓┐р▓ор│Нр▓о р▓мр│Жр▓│р│Жр▓п р▓ир│Ар▓░р▓┐р▓и р▓Ер▓Чр▓др│Нр▓пр▓Чр▓│р▓ир│Нр▓ир│Б р▓кр▓░р▓┐р▓╢р│Ар▓▓р▓┐р▓╕р▓▓р│Б р▓ир▓╛р▓ир│Б р▓╢р▓┐р▓лр▓╛р▓░р▓╕р│Б р▓ор▓╛р▓бр│Бр▓др│Нр▓др│Зр▓ир│Жред",
      "р▓Жр▓░р│Лр▓Чр│Нр▓пр▓Хр▓░ р▓мр│Жр▓│р│Ж р▓мр│Жр▓│р▓╡р▓гр▓┐р▓Чр│Жр▓Чр▓╛р▓Чр▓┐, р▓др▓╛р▓кр▓ор▓╛р▓и р▓др▓Вр▓кр▓╛р▓Чр▓┐р▓░р│Бр▓╡р▓╛р▓Ч р▓ор│Бр▓Вр▓Ьр▓╛р▓ир│Ж р▓Ьр│Ир▓╡р▓┐р▓Х р▓Чр│Кр▓мр│Нр▓мр▓░р▓╡р▓ир│Нр▓ир│Б р▓Ер▓ир│Нр▓╡р▓пр▓┐р▓╕р│Бр▓╡р│Бр▓жр▓ир│Нр▓ир│Б р▓кр▓░р▓┐р▓Чр▓гр▓┐р▓╕р▓┐ред",
      "р▓Хр│Ар▓Я р▓╣р▓╛р▓ир▓┐р▓п р▓пр▓╛р▓╡р│Бр▓жр│З р▓Ър▓┐р▓╣р│Нр▓ир│Жр▓Чр▓│р▓┐р▓Чр▓╛р▓Чр▓┐ р▓ир▓┐р▓ор│Нр▓о р▓╕р▓╕р│Нр▓пр▓Чр▓│р▓ир│Нр▓ир│Б р▓ор│Зр▓▓р│Нр▓╡р▓┐р▓Ър▓╛р▓░р▓гр│Ж р▓ор▓╛р▓бр▓┐ред",
      "р▓Хр│Кр▓пр│Нр▓▓р▓┐р▓и р▓Ер▓др│Нр▓пр│Бр▓др│Нр▓др▓о р▓╕р▓ор▓пр▓╡р│Б р▓ир▓┐р▓ор│Нр▓о р▓мр│Жр▓│р│Жр▓п р▓кр│Нр▓░р▓Хр▓╛р▓░р▓╡р▓ир│Нр▓ир│Б р▓Ер▓╡р▓▓р▓Вр▓мр▓┐р▓╕р▓┐р▓░р│Бр▓др│Нр▓др▓жр│Жред",
      "р▓ор▓гр│Нр▓гр▓┐р▓и р▓лр▓▓р▓╡р▓др│Нр▓др▓др│Жр▓пр▓ир│Нр▓ир│Б р▓Хр▓╛р▓кр▓╛р▓бр▓▓р│Б р▓мр│Жр▓│р│Ж р▓кр▓▓р│Нр▓▓р▓Яр▓╡р▓ир│Нр▓ир│Б р▓кр▓░р▓┐р▓Чр▓гр▓┐р▓╕р▓┐ред"
    ],
    pa: [
      "риорйМриЬрйВрижри╛ риорйМри╕риорйА ри╣ри╛ри▓ридри╛риВ рижрйЗ риЖризри╛ри░ 'ридрйЗ, риорйИриВ ридрйБри╣ри╛рибрйА рилри╕ри▓ рижрйА рикри╛ригрйА рижрйА ри▓рйЛрйЬ рижрйА риЬри╛риВриЪ риХри░рии рижрйА ри╕ри┐рилри╛ри░ри╕ри╝ риХри░рижри╛ ри╣ри╛риВред",
      "ри╕ри┐ри╣ридриорй░риж рилри╕ри▓ рижрйЗ ри╡ри┐риХри╛ри╕ ри▓риИ, ридри╛рикриори╛рии риарй░рибри╛ ри╣рйЛриг 'ридрйЗ ри╕ри╡рйЗри░рйЗ риЬрйИри╡ри┐риХ риЦри╛риж рижрйА ри╡ри░ридрйЛриВ риХри░рии римри╛ри░рйЗ ри╡ри┐риЪри╛ри░ риХри░рйЛред",
      "риХрйАрйЬрйЗ-риориХрйМрйЬри┐риЖриВ рижрйЗ риирйБриХри╕ри╛рии рижрйЗ риХри┐ри╕рйЗ ри╡рйА риири┐ри╕ри╝ри╛рии ри▓риИ риЖрикригрйЗ рикрйМризри┐риЖриВ рижрйА риири┐риЧри░ри╛риирйА риХри░рйЛред",
      "ри╡ри╛риврйА рижри╛ ри╕рин ридрйЛриВ ри╡ризрйАриЖ ри╕риори╛риВ ридрйБри╣ри╛рибрйА рилри╕ри▓ рижрйА риХри┐ри╕рио 'ридрйЗ риири┐ри░ринри░ риХри░рижри╛ ри╣рйИред",
      "риори┐рй▒риЯрйА рижрйА риЙри░ри╡ри░ридри╛ римригри╛риИ ри░рй▒риЦриг ри▓риИ рилри╕ри▓ риЪрй▒риХри░ римри╛ри░рйЗ ри╡ри┐риЪри╛ри░ риХри░рйЛред"
    ],
    ta: [
      "родро▒рпНрокрпЛродрпИроп ро╡ро╛ройро┐ро▓рпИ роиро┐ро▓рпИроорпИроХро│ро┐ройрпН роЕроЯро┐рокрпНрокроЯрпИропро┐ро▓рпН, роЙроЩрпНроХро│рпН рокропро┐ро░ро┐ройрпН роирпАро░рпН родрпЗро╡рпИроХро│рпИ роЪро░ро┐рокро╛ро░рпНроХрпНроХ рокро░ро┐роирпНродрпБро░рпИроХрпНроХро┐ро▒рпЗройрпН.",
      "роЖро░рпЛроХрпНроХро┐ропрооро╛рой рокропро┐ро░рпН ро╡ро│ро░рпНроЪрпНроЪро┐роХрпНроХро╛роХ, ро╡рпЖрокрпНрокроиро┐ро▓рпИ роХрпБро│ро┐ро░рпНроЪрпНроЪро┐ропро╛роХ роЗро░рпБроХрпНроХрпБроорпН роЕродро┐роХро╛ро▓рпИ роирпЗро░роЩрпНроХро│ро┐ро▓рпН роЗропро▒рпНроХрпИ роЙро░роорпН рокропройрпНрокроЯрпБродрпНродрпБро╡родрпИ рокро░ро┐роЪрпАро▓ро┐роХрпНроХро╡рпБроорпН.",
      "рокрпВроЪрпНроЪро┐ роЪрпЗродроорпН роПродрпЗройрпБроорпН роЕро▒ро┐роХрпБро▒ро┐роХро│рпБроХрпНроХро╛роХ роЙроЩрпНроХро│рпН роЪрпЖроЯро┐роХро│рпИ роХрогрпНроХро╛рогро┐роХрпНроХро╡рпБроорпН.",
      "роЕро▒рпБро╡роЯрпИропро┐ройрпН роЪро┐ро▒роирпНрод роирпЗро░роорпН роЙроЩрпНроХро│рпН рокропро┐ро░рпН ро╡роХрпИропрпИрокрпН рокрпКро▒рпБродрпНродродрпБ.",
      "роорогрпН ро╡ро│родрпНродрпИ рокро░ро╛рооро░ро┐роХрпНроХ рокропро┐ро░рпН роЪрпБро┤ро▒рпНроЪро┐ропрпИ роХро░рпБродрпНродро┐ро▓рпН роХрпКро│рпНро│ро╡рпБроорпН."
    ]
  }

  const availableResponses = responses[language as keyof typeof responses] || responses.en
  return availableResponses[Math.floor(Math.random() * availableResponses.length)]
}
