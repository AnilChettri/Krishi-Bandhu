import { NextRequest, NextResponse } from 'next/server'
import { API_CONFIG, LOCAL_AI_CONFIG } from '@/lib/api-config'
import { callLocalLLM, checkLocalAIHealth, checkOllamaHealth, checkAIBackendHealth } from '@/lib/local-llm-client'
import { createPerformanceMiddleware, trackLLMRequest, trackProviderHealth, trackFeatureUsage } from '@/lib/monitoring'

export async function POST(request: NextRequest) {
  const endpoint = 'ai-assistant'
  const performanceHandler = createPerformanceMiddleware(endpoint)
  
  return performanceHandler(async () => {
    let language = 'en' // Default language
    try {
      const requestBody = await request.json()
      const { message } = requestBody
      language = requestBody.language || 'en'

      if (!message || typeof message !== 'string') {
        return NextResponse.json(
          { 
            success: false,
            error: 'Message is required and must be a string' 
          },
          { status: 400 }
        )
      }

      // Input sanitization and validation
      const sanitizedMessage = message.slice(0, LOCAL_AI_CONFIG.SECURITY.MAX_INPUT_LENGTH)
      
      // Check for blocked patterns
      const hasBlockedPattern = LOCAL_AI_CONFIG.SECURITY.BLOCKED_PATTERNS.some(
        (pattern: RegExp) => pattern.test(sanitizedMessage)
      )
      
      if (hasBlockedPattern) {
        return NextResponse.json(
          { 
            success: false,
            error: 'Message contains blocked content' 
          },
          { status: 400 }
        )
      }
      
      // Track feature usage
      trackFeatureUsage('ai_assistant', 'chat')
    
    // Try Local AI providers first if enabled
    if (LOCAL_AI_CONFIG.ENABLED) {
      try {
        console.log('ü§ñ Using Local AI providers for farming assistance...')
        
        const startTime = Date.now()
        const localAIResponse = await callLocalLLM({
          prompt: sanitizedMessage,
          language: language,
          temperature: 0.7,
          max_tokens: 1000
        })
        
        const responseTime = Date.now() - startTime
        
        // Track LLM request metrics
        trackLLMRequest(localAIResponse.source, localAIResponse.model, responseTime, false)
        
        // Track provider health
        trackProviderHealth(localAIResponse.source, true, responseTime)

        // Log performance metrics
        console.log(`‚úÖ Local AI responded via ${localAIResponse.source} in ${responseTime}ms`)

        return NextResponse.json({
          success: true,
          response: localAIResponse.content,
          language: localAIResponse.language,
          source: localAIResponse.source,
          model: localAIResponse.model,
          response_time: localAIResponse.response_time,
          tokens_used: localAIResponse.tokens_used,
          confidence: localAIResponse.confidence,
          metadata: localAIResponse.metadata,
          timestamp: new Date().toISOString()
        })

      } catch (error) {
        console.error('‚ùå All local AI providers failed:', error)
        
        // Track provider failure
        trackProviderHealth('localai', false)
        
        // Continue to external providers as fallback
        console.log('‚ö†Ô∏è Falling back to external AI providers...')
      }
    }

    // Try OpenAI if local AI failed and API key is available
    if (API_CONFIG.OPENAI.API_KEY) {
      try {
        console.log('üåê Using OpenAI API...')
        
        const startTime = Date.now()
        
        const systemPrompt = `You are an AI farming assistant for Indian farmers. Provide practical, actionable advice about:
        - Crop cultivation and care
        - Pest and disease management  
        - Weather-based farming decisions
        - Market timing and pricing
        - Sustainable farming practices
        
        Keep responses simple, practical, and relevant to Indian agriculture. If the user asks in Hindi or other Indian languages, respond in that language.
        
        User's language preference: ${language}`

        const response = await fetch(`${API_CONFIG.OPENAI.BASE_URL}/chat/completions`, {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${API_CONFIG.OPENAI.API_KEY}`,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            model: API_CONFIG.OPENAI.MODEL,
            messages: [
              { role: 'system', content: systemPrompt },
              { role: 'user', content: sanitizedMessage }
            ],
            max_tokens: API_CONFIG.OPENAI.MAX_TOKENS,
            temperature: API_CONFIG.OPENAI.TEMPERATURE
          })
        })

        if (!response.ok) {
          throw new Error(`OpenAI API error: ${response.status}`)
        }

        const data = await response.json()
        const aiResponse = data.choices[0]?.message?.content || 'Sorry, I could not generate a response.'
        
        const responseTime = Date.now() - startTime
        
        // Track LLM request metrics
        trackLLMRequest('openai', API_CONFIG.OPENAI.MODEL, responseTime, false)
        trackProviderHealth('openai', true, responseTime)

        return NextResponse.json({
          success: true,
          response: aiResponse,
          language: language,
          source: 'openai',
          model: API_CONFIG.OPENAI.MODEL,
          response_time: responseTime,
          timestamp: new Date().toISOString()
        })

      } catch (error) {
        console.error('‚ùå OpenAI API failed:', error)
        
        // Track provider failure
        trackProviderHealth('openai', false)
      }
    }

    // Final fallback to mock response
    console.log('üîÑ Using mock response as final fallback...')
    
    const mockResponse = getMockFarmingResponse(sanitizedMessage, language)
    
    // Track fallback usage
    trackLLMRequest('mock', 'fallback', 0, false)
    
    return NextResponse.json({
      success: true,
      response: mockResponse,
      language: language,
      source: 'mock',
      model: 'fallback',
      timestamp: new Date().toISOString(),
      warning: 'Using fallback response - consider setting up local AI or external API keys'
    })

  } catch (error) {
    console.error('‚ùå AI Assistant critical error:', error)
    
    // Track critical error
    trackLLMRequest('system', 'error', 0, true)
    
    // Emergency fallback - use the language from the request or default to 'en'
    const responseLanguage = language || 'en'
    const emergencyResponse = {
      en: "I'm temporarily unable to provide assistance. Please try again in a moment, or contact your local agricultural extension office for immediate help.",
      hi: "‡§Æ‡•à‡§Ç ‡§Ö‡§∏‡•ç‡§•‡§æ‡§Ø‡•Ä ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Ö‡§∏‡§Æ‡§∞‡•ç‡§• ‡§π‡•Ç‡§Å‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§è‡§ï ‡§ï‡•ç‡§∑‡§£ ‡§Æ‡•á‡§Ç ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•á‡§Ç, ‡§Ø‡§æ ‡§§‡§§‡•ç‡§ï‡§æ‡§≤ ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§™‡§®‡•á ‡§∏‡•ç‡§•‡§æ‡§®‡•Ä‡§Ø ‡§ï‡•É‡§∑‡§ø ‡§µ‡§ø‡§∏‡•ç‡§§‡§æ‡§∞ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§≤‡§Ø ‡§∏‡•á ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§ï‡§∞‡•á‡§Ç‡•§"
    }
    
    return NextResponse.json({
      success: false,
      error: 'Service temporarily unavailable',
      response: emergencyResponse[responseLanguage as keyof typeof emergencyResponse] || emergencyResponse.en,
      source: 'emergency_fallback',
      timestamp: new Date().toISOString()
    }, { status: 500 })
  }
  })
}

// Mock farming responses for development/fallback
function getMockFarmingResponse(message: string, language: string): string {
  const responses = {
    en: [
      "Based on current weather conditions, I recommend checking your crop's water needs. Ensure proper drainage if rain is expected.",
      "For healthy crop growth, consider applying organic fertilizer during the early morning hours when temperature is cooler.",
      "Monitor your plants for any signs of pest damage. Early detection helps in better crop management.",
      "The best time for harvesting depends on your crop type. Check the color and firmness of fruits/grains regularly.",
      "Consider crop rotation to maintain soil fertility. Legumes like beans can help fix nitrogen in the soil."
    ],
    hi: [
      "‡§Æ‡•å‡§ú‡•Ç‡§¶‡§æ ‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•Ä ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞, ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§´‡§∏‡§≤ ‡§ï‡•Ä ‡§™‡§æ‡§®‡•Ä ‡§ï‡•Ä ‡§ú‡§∞‡•Ç‡§∞‡§§‡•ã‡§Ç ‡§ï‡•Ä ‡§ú‡§æ‡§Ç‡§ö ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§∏‡§≤‡§æ‡§π ‡§¶‡•á‡§§‡§æ ‡§π‡•Ç‡§Ç‡•§",
      "‡§∏‡•ç‡§µ‡§∏‡•ç‡§• ‡§´‡§∏‡§≤ ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§∏‡•Å‡§¨‡§π ‡§ú‡§≤‡•ç‡§¶‡•Ä ‡§ú‡§¨ ‡§§‡§æ‡§™‡§Æ‡§æ‡§® ‡§†‡§Ç‡§°‡§æ ‡§π‡•ã ‡§§‡§¨ ‡§ú‡•à‡§µ‡§ø‡§ï ‡§â‡§∞‡•ç‡§µ‡§∞‡§ï ‡§ï‡§æ ‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç‡•§",
      "‡§ï‡•Ä‡§ü ‡§ï‡•ç‡§∑‡§§‡§ø ‡§ï‡•á ‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§∏‡§Ç‡§ï‡•á‡§§ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§™‡§®‡•á ‡§™‡•å‡§ß‡•ã‡§Ç ‡§ï‡•Ä ‡§®‡§ø‡§ó‡§∞‡§æ‡§®‡•Ä ‡§ï‡§∞‡•á‡§Ç‡•§",
      "‡§ï‡§ü‡§æ‡§à ‡§ï‡§æ ‡§∏‡§¨‡§∏‡•á ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§∏‡§Æ‡§Ø ‡§Ü‡§™‡§ï‡•Ä ‡§´‡§∏‡§≤ ‡§ï‡•á ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§™‡§∞ ‡§®‡§ø‡§∞‡•ç‡§≠‡§∞ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§",
      "‡§Æ‡§ø‡§ü‡•ç‡§ü‡•Ä ‡§ï‡•Ä ‡§â‡§∞‡•ç‡§µ‡§∞‡§§‡§æ ‡§¨‡§®‡§æ‡§è ‡§∞‡§ñ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§´‡§∏‡§≤ ‡§ö‡§ï‡•ç‡§∞ ‡§™‡§∞ ‡§µ‡§ø‡§ö‡§æ‡§∞ ‡§ï‡§∞‡•á‡§Ç‡•§"
    ],
    kn: [
      "‡≤™‡≥ç‡≤∞‡≤∏‡≥ç‡≤§‡≥Å‡≤§ ‡≤π‡≤µ‡≤æ‡≤Æ‡≤æ‡≤® ‡≤™‡≤∞‡≤ø‡≤∏‡≥ç‡≤•‡≤ø‡≤§‡≤ø‡≤ó‡≤≥ ‡≤Ü‡≤ß‡≤æ‡≤∞‡≤¶ ‡≤Æ‡≥á‡≤≤‡≥Ü, ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤¨‡≥Ü‡≤≥‡≥Ü‡≤Ø ‡≤®‡≥Ä‡≤∞‡≤ø‡≤® ‡≤Ö‡≤ó‡≤§‡≥ç‡≤Ø‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≤∞‡≤ø‡≤∂‡≥Ä‡≤≤‡≤ø‡≤∏‡≤≤‡≥Å ‡≤®‡≤æ‡≤®‡≥Å ‡≤∂‡≤ø‡≤´‡≤æ‡≤∞‡≤∏‡≥Å ‡≤Æ‡≤æ‡≤°‡≥Å‡≤§‡≥ç‡≤§‡≥á‡≤®‡≥Ü‡•§",
      "‡≤Ü‡≤∞‡≥ã‡≤ó‡≥ç‡≤Ø‡≤ï‡≤∞ ‡≤¨‡≥Ü‡≤≥‡≥Ü ‡≤¨‡≥Ü‡≤≥‡≤µ‡≤£‡≤ø‡≤ó‡≥Ü‡≤ó‡≤æ‡≤ó‡≤ø, ‡≤§‡≤æ‡≤™‡≤Æ‡≤æ‡≤® ‡≤§‡≤Ç‡≤™‡≤æ‡≤ó‡≤ø‡≤∞‡≥Å‡≤µ‡≤æ‡≤ó ‡≤Æ‡≥Å‡≤Ç‡≤ú‡≤æ‡≤®‡≥Ü ‡≤ú‡≥à‡≤µ‡≤ø‡≤ï ‡≤ó‡≥ä‡≤¨‡≥ç‡≤¨‡≤∞‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤Ö‡≤®‡≥ç‡≤µ‡≤Ø‡≤ø‡≤∏‡≥Å‡≤µ‡≥Å‡≤¶‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≤∞‡≤ø‡≤ó‡≤£‡≤ø‡≤∏‡≤ø‡•§",
      "‡≤ï‡≥Ä‡≤ü ‡≤π‡≤æ‡≤®‡≤ø‡≤Ø ‡≤Ø‡≤æ‡≤µ‡≥Å‡≤¶‡≥á ‡≤ö‡≤ø‡≤π‡≥ç‡≤®‡≥Ü‡≤ó‡≤≥‡≤ø‡≤ó‡≤æ‡≤ó‡≤ø ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤∏‡≤∏‡≥ç‡≤Ø‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤Æ‡≥á‡≤≤‡≥ç‡≤µ‡≤ø‡≤ö‡≤æ‡≤∞‡≤£‡≥Ü ‡≤Æ‡≤æ‡≤°‡≤ø‡•§",
      "‡≤ï‡≥ä‡≤Ø‡≥ç‡≤≤‡≤ø‡≤® ‡≤Ö‡≤§‡≥ç‡≤Ø‡≥Å‡≤§‡≥ç‡≤§‡≤Æ ‡≤∏‡≤Æ‡≤Ø‡≤µ‡≥Å ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤¨‡≥Ü‡≤≥‡≥Ü‡≤Ø ‡≤™‡≥ç‡≤∞‡≤ï‡≤æ‡≤∞‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤Ö‡≤µ‡≤≤‡≤Ç‡≤¨‡≤ø‡≤∏‡≤ø‡≤∞‡≥Å‡≤§‡≥ç‡≤§‡≤¶‡≥Ü‡•§",
      "‡≤Æ‡≤£‡≥ç‡≤£‡≤ø‡≤® ‡≤´‡≤≤‡≤µ‡≤§‡≥ç‡≤§‡≤§‡≥Ü‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤ï‡≤æ‡≤™‡≤æ‡≤°‡≤≤‡≥Å ‡≤¨‡≥Ü‡≤≥‡≥Ü ‡≤™‡≤≤‡≥ç‡≤≤‡≤ü‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≤∞‡≤ø‡≤ó‡≤£‡≤ø‡≤∏‡≤ø‡•§"
    ],
    pa: [
      "‡®Æ‡©å‡®ú‡©Ç‡®¶‡®æ ‡®Æ‡©å‡®∏‡®Æ‡©Ä ‡®π‡®æ‡®≤‡®§‡®æ‡®Ç ‡®¶‡©á ‡®Ü‡®ß‡®æ‡®∞ '‡®§‡©á, ‡®Æ‡©à‡®Ç ‡®§‡©Å‡®π‡®æ‡®°‡©Ä ‡®´‡®∏‡®≤ ‡®¶‡©Ä ‡®™‡®æ‡®£‡©Ä ‡®¶‡©Ä ‡®≤‡©ã‡©ú ‡®¶‡©Ä ‡®ú‡®æ‡®Ç‡®ö ‡®ï‡®∞‡®® ‡®¶‡©Ä ‡®∏‡®ø‡®´‡®æ‡®∞‡®∏‡®º ‡®ï‡®∞‡®¶‡®æ ‡®π‡®æ‡®Ç‡•§",
      "‡®∏‡®ø‡®π‡®§‡®Æ‡©∞‡®¶ ‡®´‡®∏‡®≤ ‡®¶‡©á ‡®µ‡®ø‡®ï‡®æ‡®∏ ‡®≤‡®à, ‡®§‡®æ‡®™‡®Æ‡®æ‡®® ‡®†‡©∞‡®°‡®æ ‡®π‡©ã‡®£ '‡®§‡©á ‡®∏‡®µ‡©á‡®∞‡©á ‡®ú‡©à‡®µ‡®ø‡®ï ‡®ñ‡®æ‡®¶ ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®® ‡®¨‡®æ‡®∞‡©á ‡®µ‡®ø‡®ö‡®æ‡®∞ ‡®ï‡®∞‡©ã‡•§",
      "‡®ï‡©Ä‡©ú‡©á-‡®Æ‡®ï‡©å‡©ú‡®ø‡®Ü‡®Ç ‡®¶‡©á ‡®®‡©Å‡®ï‡®∏‡®æ‡®® ‡®¶‡©á ‡®ï‡®ø‡®∏‡©á ‡®µ‡©Ä ‡®®‡®ø‡®∏‡®º‡®æ‡®® ‡®≤‡®à ‡®Ü‡®™‡®£‡©á ‡®™‡©å‡®ß‡®ø‡®Ü‡®Ç ‡®¶‡©Ä ‡®®‡®ø‡®ó‡®∞‡®æ‡®®‡©Ä ‡®ï‡®∞‡©ã‡•§",
      "‡®µ‡®æ‡®¢‡©Ä ‡®¶‡®æ ‡®∏‡®≠ ‡®§‡©ã‡®Ç ‡®µ‡®ß‡©Ä‡®Ü ‡®∏‡®Æ‡®æ‡®Ç ‡®§‡©Å‡®π‡®æ‡®°‡©Ä ‡®´‡®∏‡®≤ ‡®¶‡©Ä ‡®ï‡®ø‡®∏‡®Æ '‡®§‡©á ‡®®‡®ø‡®∞‡®≠‡®∞ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à‡•§",
      "‡®Æ‡®ø‡©±‡®ü‡©Ä ‡®¶‡©Ä ‡®â‡®∞‡®µ‡®∞‡®§‡®æ ‡®¨‡®£‡®æ‡®à ‡®∞‡©±‡®ñ‡®£ ‡®≤‡®à ‡®´‡®∏‡®≤ ‡®ö‡©±‡®ï‡®∞ ‡®¨‡®æ‡®∞‡©á ‡®µ‡®ø‡®ö‡®æ‡®∞ ‡®ï‡®∞‡©ã‡•§"
    ],
    ta: [
      "‡Æ§‡Æ±‡Øç‡Æ™‡Øã‡Æ§‡Øà‡ÆØ ‡Æµ‡Ææ‡Æ©‡Æø‡Æ≤‡Øà ‡Æ®‡Æø‡Æ≤‡Øà‡ÆÆ‡Øà‡Æï‡Æ≥‡Æø‡Æ©‡Øç ‡ÆÖ‡Æü‡Æø‡Æ™‡Øç‡Æ™‡Æü‡Øà‡ÆØ‡Æø‡Æ≤‡Øç, ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æ™‡ÆØ‡Æø‡Æ∞‡Æø‡Æ©‡Øç ‡Æ®‡ØÄ‡Æ∞‡Øç ‡Æ§‡Øá‡Æµ‡Øà‡Æï‡Æ≥‡Øà ‡Æö‡Æ∞‡Æø‡Æ™‡Ææ‡Æ∞‡Øç‡Æï‡Øç‡Æï ‡Æ™‡Æ∞‡Æø‡Æ®‡Øç‡Æ§‡ØÅ‡Æ∞‡Øà‡Æï‡Øç‡Æï‡Æø‡Æ±‡Øá‡Æ©‡Øç.",
      "‡ÆÜ‡Æ∞‡Øã‡Æï‡Øç‡Æï‡Æø‡ÆØ‡ÆÆ‡Ææ‡Æ© ‡Æ™‡ÆØ‡Æø‡Æ∞‡Øç ‡Æµ‡Æ≥‡Æ∞‡Øç‡Æö‡Øç‡Æö‡Æø‡Æï‡Øç‡Æï‡Ææ‡Æï, ‡Æµ‡ØÜ‡Æ™‡Øç‡Æ™‡Æ®‡Æø‡Æ≤‡Øà ‡Æï‡ØÅ‡Æ≥‡Æø‡Æ∞‡Øç‡Æö‡Øç‡Æö‡Æø‡ÆØ‡Ææ‡Æï ‡Æá‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡ØÅ‡ÆÆ‡Øç ‡ÆÖ‡Æ§‡Æø‡Æï‡Ææ‡Æ≤‡Øà ‡Æ®‡Øá‡Æ∞‡Æô‡Øç‡Æï‡Æ≥‡Æø‡Æ≤‡Øç ‡Æá‡ÆØ‡Æ±‡Øç‡Æï‡Øà ‡Æâ‡Æ∞‡ÆÆ‡Øç ‡Æ™‡ÆØ‡Æ©‡Øç‡Æ™‡Æü‡ØÅ‡Æ§‡Øç‡Æ§‡ØÅ‡Æµ‡Æ§‡Øà ‡Æ™‡Æ∞‡Æø‡Æö‡ØÄ‡Æ≤‡Æø‡Æï‡Øç‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç.",
      "‡Æ™‡ØÇ‡Æö‡Øç‡Æö‡Æø ‡Æö‡Øá‡Æ§‡ÆÆ‡Øç ‡Æè‡Æ§‡Øá‡Æ©‡ØÅ‡ÆÆ‡Øç ‡ÆÖ‡Æ±‡Æø‡Æï‡ØÅ‡Æ±‡Æø‡Æï‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡Ææ‡Æï ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æö‡ØÜ‡Æü‡Æø‡Æï‡Æ≥‡Øà ‡Æï‡Æ£‡Øç‡Æï‡Ææ‡Æ£‡Æø‡Æï‡Øç‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç.",
      "‡ÆÖ‡Æ±‡ØÅ‡Æµ‡Æü‡Øà‡ÆØ‡Æø‡Æ©‡Øç ‡Æö‡Æø‡Æ±‡Æ®‡Øç‡Æ§ ‡Æ®‡Øá‡Æ∞‡ÆÆ‡Øç ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡Øç ‡Æ™‡ÆØ‡Æø‡Æ∞‡Øç ‡Æµ‡Æï‡Øà‡ÆØ‡Øà‡Æ™‡Øç ‡Æ™‡Øä‡Æ±‡ØÅ‡Æ§‡Øç‡Æ§‡Æ§‡ØÅ.",
      "‡ÆÆ‡Æ£‡Øç ‡Æµ‡Æ≥‡Æ§‡Øç‡Æ§‡Øà ‡Æ™‡Æ∞‡Ææ‡ÆÆ‡Æ∞‡Æø‡Æï‡Øç‡Æï ‡Æ™‡ÆØ‡Æø‡Æ∞‡Øç ‡Æö‡ØÅ‡Æ¥‡Æ±‡Øç‡Æö‡Æø‡ÆØ‡Øà ‡Æï‡Æ∞‡ØÅ‡Æ§‡Øç‡Æ§‡Æø‡Æ≤‡Øç ‡Æï‡Øä‡Æ≥‡Øç‡Æ≥‡Æµ‡ØÅ‡ÆÆ‡Øç."
    ]
  }

  const availableResponses = responses[language as keyof typeof responses] || responses.en
  return availableResponses[Math.floor(Math.random() * availableResponses.length)]
}
